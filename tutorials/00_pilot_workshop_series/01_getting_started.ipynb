{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25549fb7-1f29-4790-9661-bf13ca75fba6",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://img.shields.io/badge/Research%20Mode-ON-4cbb17?style=for-the-badge\" alt=\"Research Mode\">\n",
    "</p>\n",
    "\n",
    "# 01 Â· Getting Started â€” ASAP CRN Learning Lab  \n",
    "*A guided launchpad for your first ASAP-CRN workspace adventure.*\n",
    "\n",
    "Welcome to the **ASAP-CRN Learning Lab Pilot Workshop Series!**  \n",
    "\n",
    "This notebook walks you through the essentials of setting up, exploring, and running your first analyses in **Verily Workbench**.\n",
    "\n",
    "> ðŸ’¡ **Tip:** Run each cell in order for the smoothest setup experience.  \n",
    "> You can always come back later to experiment and make it your own.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8213e22-d77a-4777-92da-c964c4a5e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "# setting up environment\n",
    "import sys\n",
    "print(sys.executable)\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1200)\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    import scanpy as sc\n",
    "except ImportError as e:\n",
    "    print(\"Error -> \", e)\n",
    "    print(\"Installing scanpy\")\n",
    "    !{sys.executable} -m pip install scanpy\n",
    "    import scanpy as sc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13352458-3dac-44e9-8a35-e6252412ad46",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Workspace Orientation](#workspace-orientation)    \n",
    "2. [Setting Project Paths](#setting-project-paths)\n",
    "    - [2.1 Understanding the Path Components](#dataset-paths)\n",
    "    - [2.2 Accessing Metadata](#analysis-output-files)\n",
    "    - [2.3 Evaluating Curated Files](#metadata-files)\n",
    "3. [Exploring a Dataset](#exploring-a-dataset)  \n",
    "   - [3.1 Inspect QC Plots](#inspect-qc-plots)\n",
    "   - [3.2 Copying Data Locally](#copying-data-locally)\n",
    "   - [3.3 Preview Cell Metadata](#preview-cell-metadata)\n",
    "   - [3.4 Preview AnnData](#preview-anndata)\n",
    "5. [Reproducibility Notes](#reproducibility-notes)  \n",
    "6. [Next Steps](#next-steps)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37bd800-8489-4488-87cb-6c2527de77f3",
   "metadata": {},
   "source": [
    "## 1. Workspace Orientation\n",
    "\n",
    "In the **ASAP-CRN Learning Lab** workspace, data and resources are mounted under your home directory, typically:\n",
    "\n",
    "- `~/workspace/` â€“ workspace mount for data and outputs  \n",
    "- `~/workspace/*/asap-curated-team/` â€“ team-specific curated and derived datasets\n",
    "- `~/workspace/*/asap-curated-cohort/` â€“ multi-team curated and derived datasets  \n",
    "- `~/workspace/ws_files/` â€“ your personal scratch space for files and results  \n",
    "\n",
    "General subfolders: \n",
    "- `~/cohort_analysis` - Processed cohort-level outputs\n",
    "- `~/preprocess` - Intermediate files from data curation outputs\n",
    "In this section, weâ€™ll confirm these paths and see whatâ€™s available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8864ee-52c6-4ae3-996e-a51127eee846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home directory:      /home/jupyter\n",
      "Workspace root:      /home/jupyter/workspace\n",
      "Data directory:      /home/jupyter/workspace/Data\n",
      "ws_files directory:  /home/jupyter/workspace/ws_files\n",
      "\n",
      "Contents of workspace root:\n",
      " - 02_PMDBS_bulkRNAseq /\n",
      " - 05_Other_Datasets /\n",
      " - 04_Mouse_Spatial /\n",
      " - ws_files /\n",
      " - release_resources /\n",
      " - Documentation /\n",
      " - 03_PMDBS_Spatial /\n",
      " - 01_PMDBS_scRNAseq /\n"
     ]
    }
   ],
   "source": [
    "#set general folder paths\n",
    "HOME = Path.home()\n",
    "WS_ROOT = HOME / \"workspace\"\n",
    "DATA_DIR = WS_ROOT / \"Data\"\n",
    "WS_FILES = WS_ROOT / \"ws_files\"\n",
    "\n",
    "if not WS_ROOT.exists():\n",
    "    print(f\"{WS_ROOT} doesn't exist. We need to remount our resources\")\n",
    "    !wb resource mount    \n",
    "\n",
    "print(\"Home directory:     \", HOME)\n",
    "print(\"Workspace root:     \", WS_ROOT)\n",
    "print(\"Data directory:     \", DATA_DIR)\n",
    "print(\"ws_files directory: \", WS_FILES)\n",
    "\n",
    "print(\"\\nContents of workspace root:\")\n",
    "for p in WS_ROOT.glob(\"*\"):\n",
    "    print(\" -\", p.name, \"/\" if p.is_dir() else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0ca9a-567c-4d30-a4b1-05f406579c74",
   "metadata": {},
   "source": [
    "## 2. Setting Project Paths\n",
    "\n",
    "For the next steps, we will work with datasets processed using the **PMDBS scRNAseq** workflow. Specifically, we will focus on the **cohort-level dataset**: `asap-cohort-pmdbs-sc-rnaseq`.  \n",
    "\n",
    "This dataset represents a multi-dataset integration: samples from **five contributing datasets**, processed, curated, and harmonized into a single cohort resource.\n",
    "\n",
    "### 2.1 Understanding the Path Components\n",
    "The dataset paths follow a structured hierarchy. Each component has a specific meaning:\n",
    "\n",
    "- **`workflow`** â€” identifies the workflow used for aggregation and integration.  \n",
    "  Here we use the **[PMDBS scRNAseq workflow](https://github.com/ASAP-CRN/pmdbs-sc-rnaseq-wf)**.\n",
    "\n",
    "- **`dataset_team`** â€” identifies the contributing team or grouping of datasets. For cohort-level analyses, this value is **`cohort`**, indicating multiple datasets combined.\n",
    "\n",
    "- **`source`** â€” describes the biological source of the samples.  \n",
    "  In this case, **`pmdbs`** refers to *post-mortemâ€“derived brain samples*.\n",
    "\n",
    "- **`dataset_type`** â€” describes the type of data generated.  \n",
    "  Here it is **`sc-rnaseq`**, indicating single-cell RNA sequencing.\n",
    "\n",
    "- **`bucket_name`** â€” the Google Cloud Storage bucket containing the curated dataset.\n",
    "\n",
    "- **`dataset_name`** â€” a unique identifier for each curated dataset or collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6148ee04-3517-4126-be83-580266a87279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: /home/jupyter/workspace/01_PMDBS_scRNAseq/asap-curated-cohort-pmdbs-sc-rnaseq/pmdbs_sc_rnaseq\n"
     ]
    }
   ],
   "source": [
    "## Build and set path to desired dataset\n",
    "\n",
    "DATASETS_PATH = WS_ROOT / \"01_PMDBS_scRNAseq\"\n",
    "\n",
    "workflow       = \"pmdbs_sc_rnaseq\"\n",
    "dataset_team   = \"cohort\"\n",
    "dataset_source = \"pmdbs\"\n",
    "dataset_type   = \"sc-rnaseq\"\n",
    "\n",
    "bucket_name  = f\"asap-curated-{dataset_team}-{dataset_source}-{dataset_type}\"\n",
    "dataset_name = f\"asap-{dataset_team}-{dataset_source}-{dataset_type}\"\n",
    "\n",
    "dataset_path = DATASETS_PATH / bucket_name / workflow\n",
    "print(\"Dataset Path:\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884d43b0-eef0-436d-a130-2020c378121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_analysis_path = dataset_path / \"cohort_analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1628ef1-e9d0-4589-9fc5-bd7edf1398fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/jupyter/workspace/01_PMDBS_scRNAseq/asap-curated-cohort-pmdbs-sc-rnaseq/pmdbs_sc_rnaseq/cohort_analysis': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls  {cohort_analysis_path} \n",
    "# pythonic way: \n",
    "# [f.name for f in cohort_analysis_path.glob(\"**/*\") if f.is_file()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d5ff8-bf12-4e03-bb4d-2f9ec85e87bf",
   "metadata": {},
   "source": [
    "## 2.2 Accessing Metadata Files\n",
    "\n",
    "Metadata for each dataset is located within the `release_resources` directory. See the [Data Dictionary](https://storage.googleapis.com/asap-public-assets/wayfinding/ASAP-CRN-Cloud-Data-Dictionary.pdf) for an overview of the metadata tables.\n",
    "\n",
    "> **Note:**  \n",
    "> Metadata files are organized using the **short `dataset_name`**, not the `bucket_name`.  \n",
    "> You can always use the File Browser tab of the side panel to explore directories and right-click any folder or file to copy its full path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01574536-e1d7-4cd8-86d7-68ba2bae75f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/jupyter/workspace/release_resources/cohort-pmdbs-sc-rnaseq/metadata': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#Define metadata folder path\n",
    "ds_metadata_path = WS_ROOT / \"release_resources/cohort-pmdbs-sc-rnaseq/metadata\"\n",
    "\n",
    "#preview contents\n",
    "!ls {ds_metadata_path} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29f41592-b2ce-487e-8c04-05d5c5355511",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jupyter/workspace/release_resources/cohort-pmdbs-sc-rnaseq/metadata/CONDITION.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# preview a dataset metadata file \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m display(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_metadata_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCONDITION.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/envs/jupyter/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jupyter/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/envs/jupyter/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jupyter/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/envs/jupyter/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jupyter/workspace/release_resources/cohort-pmdbs-sc-rnaseq/metadata/CONDITION.csv'"
     ]
    }
   ],
   "source": [
    "# preview a dataset metadata file \n",
    "display(pd.read_csv(ds_metadata_path / \"CONDITION.csv\", index_col=0).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a14c02-047b-416c-9a7e-47a02cef2297",
   "metadata": {},
   "source": [
    "### 2.3 Inspecting Curated Files\n",
    "\n",
    "Now that our path components are defined, we can inspect the curated files available in the cohort_analysis directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaebfab-4030-428d-8a1f-c03ed6dca205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the folder path to the cohort analysis directory\n",
    "cohort_analysis_path = dataset_path / \"cohort_analysis\"\n",
    "\n",
    "# Preview the directory contents\n",
    "print(\"Contents of cohort_analysis:\")\n",
    "!ls {cohort_analysis_path}\n",
    "\n",
    "# Optional pure-Python preview:\n",
    "# [f.name for f in cohort_analysis_path.glob(\"**/*\") if f.is_file()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63982a9-9ce9-4d03-b28c-c28ad48fe241",
   "metadata": {},
   "source": [
    "## 3. Exploring a Dataset\n",
    "\n",
    "With the directory structure in place, we can begin exploring the processed outputs produced by the PMDBS scRNA-seq workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b2090-9444-4ad0-b987-267a372757aa",
   "metadata": {},
   "source": [
    "### 3.1 Inspect QC Plots\n",
    "\n",
    "The curated dataset includes several **QC violin plots** summarizing key metrics (e.g., doublet score, gene counts, mitochondrial content). Letâ€™s load and display all violin plot images found in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5626c7e-235e-430f-811f-1af3a729e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all violin plot images\n",
    "images = [\n",
    "    os.path.join(cohort_analysis_path, f)\n",
    "    for f in os.listdir(cohort_analysis_path)\n",
    "    if f.lower().endswith(\"violin.png\")\n",
    "]\n",
    "\n",
    "n = len(images)\n",
    "if n == 0:\n",
    "    print(\"No violin plots found in cohort_analysis.\")\n",
    "else:\n",
    "    cols = 3\n",
    "    rows = math.ceil(n / cols)\n",
    "\n",
    "    plt.figure(figsize=(14, 4 * rows))\n",
    "\n",
    "    for i, img_path in enumerate(images):\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(os.path.basename(img_path), fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91887a86-8899-416f-99a3-f3c51104539f",
   "metadata": {},
   "source": [
    "### 3.2 Downloading data files locally\n",
    "\n",
    "In this step, weâ€™ll set up a local directory inside our JupyterLab environment to store data files.  The `ws_files` area is a scratch space tied to your workspace â€” anything saved here can be accessed later in the notebook, processed with Python, or uploaded back to a workspace bucket for sharing.\n",
    "\n",
    "Weâ€™ll create a folder called `workshop_files` under our workspace path (`WS_PATH`).  This ensures that all downloaded datasets are organized in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c82daf-5dc2-4c9b-bee0-3878b7196cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a local path for workshop files\n",
    "local_data_path = WS_FILES / \"pilot_workshop_files\"\n",
    "\n",
    "# Create the directory if it doesn't already exist\n",
    "if not local_data_path.exists():\n",
    "    local_data_path.mkdir(parents=True)\n",
    "\n",
    "print(f\"Local data directory ready at: {local_data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82582c-1697-4b64-91f4-c538c37f4897",
   "metadata": {},
   "source": [
    "We can now download the curated `anndata object` and it's associated `obs` field locally into our workspace.\n",
    "> **Note:**\n",
    "> It is recommended to download desired data locally before loading into notebook to be more efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5a720b8-0091-4e13-a336-bd461767fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading obs field (cell metadata)\n",
    "# Define the expected local path for the metadata file.\n",
    "cell_metadata_local_path = local_data_path / f\"asap-{dataset_team}.final_metadata.csv\"\\\n",
    "\n",
    "# Check if the metadata file already exists locally.\n",
    "if not cell_metadata_local_path.exists():\n",
    "    # Construct the original path where the metadata file is stored.\n",
    "    cell_metadata_og_path = cohort_analysis_path / f\"asap-{dataset_team}.final_metadata.csv\"\n",
    "\n",
    "    # Use a shell command (`cp`) to copy the file from the original location\n",
    "    # into the local workshop_files directory for analysis.\n",
    "    !cp {cell_metadata_og_path} {cell_metadata_local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509b09fe-317f-4756-84f9-5f3ca3d7aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the anndata object\n",
    "# Define the expected local path\n",
    "adata_local_path = local_data_path / f\"asap-{dataset_team}.final.h5ad\"\n",
    "\n",
    "# Check if the adata file already exists locally.\n",
    "if not adata_local_path.exists():\n",
    "    # Construct the original path where the metadata file is stored.\n",
    "    adata_cell_metadata_og_path = cohort_analysis_path / f\"asap-{dataset_team}.final.h5ad\"\n",
    "\n",
    "    # Use a shell command (`cp`) to copy the file from the original location\n",
    "    # into the local workshop_files directory for analysis.\n",
    "    !cp {adata_cell_metadata_og_path} {adata_local_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a19eb-776f-4e4d-821e-d25bcf170992",
   "metadata": {},
   "source": [
    "### 3.3 Exploring the Cell Metadata\n",
    "\n",
    "Once the data is available in our `workshop_files` directory, we can begin exploring its metadata.\n",
    "\n",
    "This field provides a compact entry point into the datasetâ€™s metadata, making it easier to explore without handling the full expression matrix.\n",
    "\n",
    "Each row in `obs` corresponds to a single cell (identified by a unique *barcode*) and contains:\n",
    "\n",
    "- **Quality control metrics**: e.g. CellBender `cell_probability`, `n_genes_by_counts`, `total_counts`.  \n",
    "- **Dataset references**: e.g. `sample`, `batch`, `team`, `dataset`.  \n",
    "- **Downstream analysis results**: e.g. `UMAP_1`, `UMAP_2`, CellAssign `cell_type`, and Leiden cluster assignments.  \n",
    "\n",
    "Together, these annotations summarize the key observations for each cell and provide a rich foundation for both quality assessment and downstream biological interpretation..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1c9dd9d-a863-4aab-8625-a06ad76043fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have loaded the cell_metadata for N=3046127 cells\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'background_fraction',\n",
       " 'cell_probability',\n",
       " 'cell_size',\n",
       " 'droplet_efficiency',\n",
       " 'n_genes_by_counts',\n",
       " 'total_counts',\n",
       " 'total_counts_rb',\n",
       " 'pct_counts_rb',\n",
       " 'total_counts_mt',\n",
       " 'pct_counts_mt',\n",
       " 'doublet_score',\n",
       " 'sample',\n",
       " 'batch',\n",
       " 'team',\n",
       " 'dataset',\n",
       " 'batch_id',\n",
       " 'S_score',\n",
       " 'G2M_score',\n",
       " 'phase',\n",
       " 'cell_type',\n",
       " 'phenotype',\n",
       " 'rho',\n",
       " 'prob',\n",
       " 'class_name',\n",
       " 'subclass_name',\n",
       " 'supertype_name',\n",
       " '_scvi_batch',\n",
       " '_scvi_labels',\n",
       " 'C_scANVI',\n",
       " 'leiden_res_0.05',\n",
       " 'leiden_res_0.10',\n",
       " 'leiden_res_0.20',\n",
       " 'leiden_res_0.40',\n",
       " 'UMAP_1',\n",
       " 'UMAP_2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the adata object metadata\n",
    "cell_metadata_df = pd.read_csv(cell_metadata_local_path, low_memory=False)\n",
    "print(f\"We have loaded the cell_metadata for N={cell_metadata_df.shape[0]} cells\")\n",
    "# Preview the contents \n",
    "cell_metadata_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e265e4-2403-4b59-81b8-6e28fa0f1d9e",
   "metadata": {},
   "source": [
    "### 3.4 Exploring the AnnData\n",
    "\n",
    "With the curated dataset stored locally, we can load it into memory using the `scanpy` library.  The data is stored in an **AnnData** object (`.h5ad` format), which is a common structure for singleâ€‘cell analysis.  \n",
    "\n",
    "AnnData organizes the dataset into:\n",
    "- **`.X`** â†’ the main data matrix (e.g., gene expression counts).  \n",
    "- **`.obs`** â†’ perâ€‘cell annotations (metadata such as QC metrics, sample IDs, cell types).  \n",
    "- **`.var`** â†’ perâ€‘feature annotations (metadata about genes/features).  \n",
    "- **`.uns`** â†’ unstructured annotations (analysis results, parameters, plots).  \n",
    "\n",
    "Weâ€™ll load the file in *backed mode* (`backed=\"r\"`), which allows us to access the object without reading the entire matrix into memory â€” useful for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00662320-0c72-4e80-bc4f-db8ecf926136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 3046127 Ã— 3000 backed at '/home/jupyter/workspace/ws_files/pilot_workshop_files/asap-cohort.final.h5ad'\n",
       "    obs: 'background_fraction', 'cell_probability', 'cell_size', 'droplet_efficiency', 'n_genes_by_counts', 'total_counts', 'total_counts_rb', 'pct_counts_rb', 'total_counts_mt', 'pct_counts_mt', 'doublet_score', 'sample', 'batch', 'team', 'dataset', 'batch_id', 'S_score', 'G2M_score', 'phase', 'cell_type', 'phenotype', 'rho', 'prob', 'class_name', 'subclass_name', 'supertype_name', '_scvi_batch', '_scvi_labels', 'C_scANVI', 'leiden_res_0.05', 'leiden_res_0.10', 'leiden_res_0.20', 'leiden_res_0.40'\n",
       "    var: 'feature_type', 'genome', 'gene_id', 'mt', 'rb'\n",
       "    uns: '_scvi_manager_uuid', '_scvi_uuid', 'estimator', 'fraction_data_used_for_testing', 'learning_curve_learning_rate_epoch', 'learning_curve_test_epoch', 'learning_curve_train_epoch', 'leiden_res_0.05', 'leiden_res_0.10', 'leiden_res_0.20', 'leiden_res_0.40', 'log1p', 'neighbors', 'pca', 'scrublet', 'target_false_positive_rate', 'umap'\n",
       "    obsm: 'X_pca', 'X_pca_harmony', 'X_scANVI', 'X_scVI', 'X_umap', 'gene_expression_encoding'\n",
       "    varm: 'PCs'\n",
       "    layers: 'counts'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the curated AnnData object in backed mode\n",
    "adata = sc.read_h5ad(adata_local_path, backed=\"r\")\n",
    "\n",
    "# Display a summary of the AnnData object\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e794c81f-5b0a-45b4-8374-20406544c7af",
   "metadata": {},
   "source": [
    "The above summary shows the number of cells (rows) and genes (columns), along with available annotations.  \n",
    "\n",
    "Next, letâ€™s visualize the dataset using a UMAP embedding to explore how cells are distributed by their assigned cell type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e672f7ac-c8d5-4d25-bf7b-a01ef8677ccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot a UMAP embedding colored by cell type\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msc\u001b[49m\u001b[38;5;241m.\u001b[39mpl\u001b[38;5;241m.\u001b[39membedding(adata, basis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mumap\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot a UMAP embedding colored by cell type\n",
    "sc.pl.embedding(adata, basis=\"umap\", color=[\"cell_type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d69f45-f9df-4be3-a889-4d316348dba6",
   "metadata": {},
   "source": [
    "## 5. Reproducibility / Versioning Notes\n",
    "\n",
    "To keep analyses reproducible and collaborative:\n",
    "\n",
    "- **Record environment details**: note Python version and key package versions (`scanpy`, `pandas`, etc.).\n",
    "- **Save intermediate outputs**: store curated files and metadata snapshots in `ws_files`.\n",
    "- **Use Git for version control**: commit notebooks and scripts to a shared repository.\n",
    "- **Document changes**: add notes in Markdown cells or a changelog section at the end of the notebook.\n",
    "\n",
    "These practices make it easier for collaborators (and your future self) to reproduce results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8cc28-83fd-4a3a-b32b-fdaea9d70b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb4b5e3-0a0e-4ebb-9196-8c39d32686ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter labextension list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22944310-e729-412a-92c7-4c45daeaa939",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep ^processor /proc/cpuinfo | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef95cd-ac7a-4809-b1bd-40577f71dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep \"^MemTotal:\" /proc/meminfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a8d45-bb36-4ffb-aff5-27b59ed4c0df",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "This notebook introduced:\n",
    "- Orienting your workspace\n",
    "- Loading and inspecting data resources\n",
    "- Saving outputs for sharing\n",
    "\n",
    "ðŸ‘‰ Continue to the next notebook: **[02_data_exploration.ipynb](./02_data_exploration.ipynb)**  \n",
    "There weâ€™ll dive deeper into clustering, differential expression, and biological interpretation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
