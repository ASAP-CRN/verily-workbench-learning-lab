{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79cc8363",
   "metadata": {},
   "source": [
    "<p align=\"left\">\n",
    "  <img src=\"https://img.shields.io/badge/Research%20Mode-ON-4cbb17?style=for-the-badge\" alt=\"Research Mode\">\n",
    "</p>\n",
    "\n",
    "# 02 Â· Data Exploration â€” ASAP CRN Learning Lab  \n",
    "*A guided launchpad for your second ASAP-CRN workspace adventure.*\n",
    "\n",
    "Welcome to the **ASAP-CRN Learning Lab Pilot Workshop Series!**  \n",
    "\n",
    "This notebook walks you through the essentials of data inspection and preliminary analyses in **Verily Workbench**.\n",
    "\n",
    "> ðŸ’¡ **Tip:** Run each cell in order for the smoothest setup experience.  \n",
    "> You can always come back later to experiment and make it your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7edfd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amaraalexander/miniconda3/envs/ASAP-CRN/bin/python\n",
      "Error ->  No module named 'scanpy'\n",
      "Installing scanpy\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 25.9.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.9.1\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scanpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscanpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msc\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scanpy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInstalling scanpy\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mconda install scanpy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscanpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msc\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scanpy'"
     ]
    }
   ],
   "source": [
    "# setting up environment\n",
    "import sys\n",
    "print(sys.executable)\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1200)\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    import scanpy as sc\n",
    "except ImportError as e:\n",
    "    print(\"Error -> \", e)\n",
    "    print(\"Installing scanpy\")\n",
    "    !conda install scanpy\n",
    "    import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc0ced6",
   "metadata": {},
   "source": [
    "### Set Project Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ddd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set general folder paths\n",
    "HOME = Path.home()\n",
    "WS_ROOT = HOME / \"workspace\"\n",
    "DATA_DIR = WS_ROOT / \"Data\"\n",
    "WS_FILES = WS_ROOT / \"ws_files\"\n",
    "\n",
    "if not WS_ROOT.exists():\n",
    "    print(f\"{WS_ROOT} doesn't exist. We need to remount our resources\")\n",
    "    !wb resource mount    \n",
    "\n",
    "print(\"Home directory:     \", HOME)\n",
    "print(\"Workspace root:     \", WS_ROOT)\n",
    "print(\"Data directory:     \", DATA_DIR)\n",
    "print(\"ws_files directory: \", WS_FILES)\n",
    "\n",
    "print(\"\\nContents of workspace root:\")\n",
    "for p in WS_ROOT.glob(\"*\"):\n",
    "    print(\" -\", p.name, \"/\" if p.is_dir() else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build and set path to desired dataset\n",
    "\n",
    "DATASETS_PATH = WS_ROOT / \"01_PMDBS_scRNAseq\"\n",
    "\n",
    "workflow       = \"pmdbs_sc_rnaseq\"\n",
    "dataset_team   = \"cohort\"\n",
    "dataset_source = \"pmdbs\"\n",
    "dataset_type   = \"sc-rnaseq\"\n",
    "\n",
    "bucket_name  = f\"asap-curated-{dataset_team}-{dataset_source}-{dataset_type}\"\n",
    "dataset_name = f\"asap-{dataset_team}-{dataset_source}-{dataset_type}\"\n",
    "\n",
    "dataset_path = DATASETS_PATH / bucket_name / workflow\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "cohort_analysis_path = dataset_path / \"cohort_analysis\"\n",
    "\n",
    "!ls  {cohort_analysis_path} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292afbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define metadata folder path\n",
    "ds_metadata_path = WS_ROOT / \"release_resources/cohort-pmdbs-sc-rnaseq/metadata\"\n",
    "\n",
    "#preview contents\n",
    "!ls {ds_metadata_path} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8841b",
   "metadata": {},
   "source": [
    "If not already created, create a local directory store any outputs to retain and share. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a local path for workshop files\n",
    "local_data_path = WS_FILES / \"pilot_workshop_files\"\n",
    "\n",
    "# Create the directory if it doesn't already exist\n",
    "if not local_data_path.exists():\n",
    "    local_data_path.mkdir(parents=True)\n",
    "\n",
    "print(f\"Local data directory ready at: {local_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bb2fb",
   "metadata": {},
   "source": [
    "### Load in Data \n",
    "\n",
    "We will use: \n",
    "- asap-cohort.final_metadata.csv\n",
    "- asap-cohort.final.h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the expected local path\n",
    "cell_metadata_local_path = local_data_path / f\"asap-{dataset_team}.final_metadata.csv\"\n",
    "if not cell_metadata_local_path.exists():\n",
    "    cell_metadata_og_path = cohort_analysis_path / f\"asap-{dataset_team}.final_metadata.csv\"\n",
    "    !cp {cell_metadata_og_path} {cell_metadata_local_path}\n",
    "\n",
    "# load the adata object\n",
    "cell_metadata_df = pd.read_csv(cell_metadata_local_path, low_memory=False)\n",
    "print(f\"We have loaded the cell_metadata for N={cell_metadata_df.shape[0]} cells\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fae7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_local_path = local_data_path / f\"asap-{dataset_team}.final.h5ad\"\n",
    "\n",
    "# Check if the adata file already exists locally.\n",
    "if not adata_local_path.exists():\n",
    "    adata_cell_metadata_og_path = cohort_analysis_path / f\"asap-{dataset_team}.final.h5ad\"\n",
    "    !cp {adata_cell_metadata_og_path} {adata_local_path}\n",
    "\n",
    "adata = sc.read_h5ad(adata_local_path, backed=\"r\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c76199",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "Now, that we have both data loaded we can begin exploring the contents further. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a2253a",
   "metadata": {},
   "source": [
    "#### Merging dataset metadata with cell-metadata\n",
    "\n",
    "We will leverage the available metadatas to subset the data for cells of interest  \n",
    "First lets load some of the _dataset_-metadata and map this information into our _cell_-metadata.\n",
    "This will be used to annotate experimental conditions into our _cell_-level metadata.    In the next section we will use this to create subsets of our `asap-cohort` PMDBS snRNAseq dataset, and encode Parkinson's disease state.\n",
    "\n",
    "Specifically we'll combine Sample-level, Subject-level, PMDBS specific  and experimental condition metadata, by combining the `SAMPLE`, `SUBJECT`, `PMDBS`, and `CONDITION` tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample-level metadata\n",
    "SAMPLE = pd.read_csv(ds_metadata_path / \"SAMPLE.csv\", index_col=0)\n",
    "# subject-level metadata\n",
    "SUBJECT = pd.read_csv(ds_metadata_path / \"SUBJECT.csv\", index_col=0)\n",
    "#  brain-sample metadata\n",
    "PMDBS = pd.read_csv(ds_metadata_path / \"PMDBS.csv\", index_col=0)\n",
    "# experimental condition metadata\n",
    "CONDITION = pd.read_csv(ds_metadata_path / \"CONDITION.csv\", index_col=0)\n",
    "\n",
    "# Just take a few of the columns which we need\n",
    "sample_cols = [\n",
    "    \"ASAP_sample_id\",\n",
    "    \"ASAP_subject_id\",\n",
    "    \"ASAP_team_id\",\n",
    "    \"ASAP_dataset_id\",\n",
    "    \"replicate\",\n",
    "    \"condition_id\",\n",
    "]\n",
    "subject_cols = [\n",
    "    \"ASAP_subject_id\",\n",
    "    \"source_subject_id\",\n",
    "    \"sex\",\n",
    "    \"age_at_collection\",\n",
    "    \"primary_diagnosis\",\n",
    "]\n",
    "pmdbs_cols = [\n",
    "    \"ASAP_sample_id\",\n",
    "    \"brain_region\",\n",
    "    \"region_level_1\",\n",
    "    \"region_level_2\",\n",
    "    \"region_level_3\",\n",
    "]\n",
    "condition_cols = [\n",
    "    \"condition_id\",\n",
    "    \"intervention_name\",\n",
    "    \"intervention_id\",\n",
    "    \"protocol_id\",\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASAP-CRN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
